#!/usr/bin/env python3
# encoding: utf-8
#物体位姿计算
import cv2
import time
import rclpy
import numpy as np
from sdk import common
from rclpy.node import Node
from cv_bridge import CvBridge
from sensor_msgs.msg import Image as RosImage, CameraInfo
 

class CoordinateTransformation(Node):
    def __init__(self, name):
        rclpy.init()
        super().__init__(name, allow_undeclared_parameters=True, automatically_declare_parameters_from_overrides=True)
        self.bridge = CvBridge()  # 用于ROS Image消息与OpenCV图像之间的转换
        self.K = None
        with open(self.config_path + self.config_file, 'r') as f:
            config = yaml.safe_load(f)

            # 转换为 numpy 数组
            extristric = np.array(config['extristric'])
            white_area_pose_world = np.array(config['white_area_pose_world'])
            tvec = extristric[:1]  # 取第一行
            rmat = extristric[1:]  # 取后面三行
        tvec, rmat = common.extristric_plane_shift(np.array(tvec).reshape((3, 1)), np.array(rmat), 0.030)
        self.extristric = tvec, rmat
        white_area_center = white_area_pose_world.reshape(4, 4)
        self.white_area_center = white_area_center

        # 订阅图像话题
        self.image_sub = self.create_subscription(RosImage, '/color_detection/result_image', self.image_callback, 1)
        self.camera_info_sub = self.create_subscription(CameraInfo, '/depth_cam/depth/camera_info', self.camera_info_callback, 1)

    def camera_info_callback(self, msg):
        self.K = np.matrix(msg.k).reshape(1, -1, 3)

    # 处理ROS节点数据
    def image_callback(self, result_image):
        try:
            
            # 将 ROS Image 消息转换为 OpenCV 图像
            bgr_image = self.bridge.imgmsg_to_cv2(result_image, "bgr8")

            # 将灰度图像转换为 BGR 图像
            result_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)


            if result_image is not None :
                # 计算识别到的轮廓
                contours = cv2.findContours(result_image, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)[-2]  # 找出所有轮廓

                if contours :

                    # 找出最大轮廓
                    c = max(contours, key = cv2.contourArea)
                    # 根据轮廓大小判断是否进行下一步处理
                    rect = cv2.minAreaRect(c)  # 获取最小外接矩形
                    corners = np.int0(cv2.boxPoints(rect))  # 获取最小外接矩形的四个角点
                    x, y = rect[0][0],rect[0][1]
                    # 打印像素坐标
                    self.get_logger().info(f"像素坐标为: x: {x}, y: {y}")


                    projection_matrix = np.row_stack((np.column_stack((self.extristric[1],self.extristric[0])), np.array([[0, 0, 0, 1]])))
                    world_pose = common.pixels_to_world([[x,y]], self.K, projection_matrix)[0]
                    world_pose[1] = -world_pose[1]
                    world_pose[2] = 0.03
                    world_pose = np.matmul(self.white_area_center, common.xyz_euler_to_mat(world_pose, (0, 0, 0)))
                    world_pose[2] = 0.03
                    pose_t, _ = common.mat_to_xyz_euler(world_pose)
                    self.get_logger().info(f"实际坐标为： {pose_t}")
                else:
                    self.get_logger().info("未检测到所需识别的颜色，请将色块放置到相机视野内。")

        except Exception as e:
            print(e)

def main():
    node = CoordinateTransformation('coordinate_transformation')
    rclpy.spin(node)
    camera_node.destroy_node()
    
    rclpy.shutdown()
        
if __name__ == '__main__':
    main()
